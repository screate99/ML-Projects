{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j8BuQEXP2byA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_curve, auc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prYxhCgo3G_L"
   },
   "source": [
    "# Business Objective\n",
    "**The primary objective is to identify the most effective classification model for predicting customer subscription to bank products based on historical campaign data. This will enable the bank to focus its marketing resources on the most promising leads, thereby maximizing the return on investment for marketing activities.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TccjfE9O34jX"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/bank-additional-full.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JfIsMnF74wXj"
   },
   "source": [
    "# Analyze quality of the data and clean up data\n",
    "\n",
    " * Will generate two data frame df and df_cleaned. df is the original data with droppong record and imputation. df_cleaned is the data frame with data clean up.\n",
    " * Will apply model to both to confirm if data clean up have any impact on the feature engineering and modeling accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 508,
     "status": "ok",
     "timestamp": 1717370381972,
     "user": {
      "displayName": "Shirley liu",
      "userId": "04876526516659009918"
     },
     "user_tz": 420
    },
    "id": "wrQve5bQ4jRm",
    "outputId": "c78889a6-50d3-46d2-e449-99cb227df902"
   },
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Displaying columns with missing values\n",
    "missing_columns = missing_values[missing_values > 0]\n",
    "if not missing_columns.empty:\n",
    "    print(\"Columns with Missing Values:\\n\", missing_columns)\n",
    "else:\n",
    "    print(\"No missing values in any column.\")\n",
    "\n",
    "# Checking for duplicate rows\n",
    "duplicate_rows = df.duplicated().sum()\n",
    "if duplicate_rows > 0:\n",
    "    print(\"\\nNumber of Duplicate Rows: \", duplicate_rows)\n",
    "    # Displaying duplicate rows\n",
    "    duplicate_data = df[df.duplicated()]\n",
    "    print(\"\\nDuplicate Rows:\\n\", duplicate_data)\n",
    "else:\n",
    "    print(\"\\nNo duplicate rows found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8DU73wz26kHR"
   },
   "outputs": [],
   "source": [
    "# Removing duplicate rows\n",
    "df_cleaned = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 374,
     "status": "ok",
     "timestamp": 1717370393263,
     "user": {
      "displayName": "Shirley liu",
      "userId": "04876526516659009918"
     },
     "user_tz": 420
    },
    "id": "SiS3Ry406pRP",
    "outputId": "8716ae57-4133-4723-f08d-af6590d21f98"
   },
   "outputs": [],
   "source": [
    "# analyze unknown values\n",
    "object_columns = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "unknown_summary = {}\n",
    "for column in object_columns:\n",
    "    total_values = len(df[column])\n",
    "    unknown_values = (df[column] == 'unknown').sum()\n",
    "    percentage_unknown = (unknown_values / total_values) * 100\n",
    "    unknown_summary[column] = percentage_unknown\n",
    "\n",
    "# Displaying the percentage of unknown values per object column\n",
    "print(\"Percentage of unknown values per object column:\\n\")\n",
    "for column, percentage in unknown_summary.items():\n",
    "    print(f\"{column}: {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6427,
     "status": "ok",
     "timestamp": 1717370403468,
     "user": {
      "displayName": "Shirley liu",
      "userId": "04876526516659009918"
     },
     "user_tz": 420
    },
    "id": "TlmhpQKm-FIy",
    "outputId": "27c092e0-b2e9-4b97-8e2a-2d1224209552"
   },
   "outputs": [],
   "source": [
    "# Understand the distribution of unknown values on the rows\n",
    "# Check for unknown values in all object columns\n",
    "object_columns = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Compute the number of unknown values per row\n",
    "df['unknown_count'] = df[object_columns].apply(lambda row: (row == 'unknown').sum(), axis=1)\n",
    "\n",
    "# Count rows with different numbers of unknown values\n",
    "unknown_count_distribution = df['unknown_count'].value_counts().sort_index()\n",
    "\n",
    "# Total number of records\n",
    "total_records = len(df)\n",
    "\n",
    "# Displaying the distribution of rows with 1 to 6 columns having unknown values\n",
    "for i in range(1, len(object_columns) + 1):\n",
    "    count = unknown_count_distribution.get(i, 0)\n",
    "    percentage = (count / total_records) * 100\n",
    "    print(f\"Number of rows with {i} column(s) having 'unknown' value: {count} ({percentage:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_T-R7B7X_ZHy"
   },
   "outputs": [],
   "source": [
    "# Try to handle  unknown values with df_cleaned data\n",
    "# Impute function for mode\n",
    "def impute_mode(df, column):\n",
    "    mode_value = df[column].mode()[0]\n",
    "    df.loc[df[column] == 'unknown', column] = mode_value\n",
    "\n",
    "# Impute function for creating a new category\n",
    "def impute_new_category(df, column, new_category):\n",
    "    df.loc[df[column] == 'unknown', column] = new_category\n",
    "\n",
    "# Impute missing values based on strategy\n",
    "impute_mode(df_cleaned, 'job')\n",
    "impute_mode(df_cleaned, 'marital')\n",
    "impute_mode(df_cleaned, 'education')\n",
    "impute_new_category(df_cleaned, 'default', 'unknown_default')\n",
    "impute_mode(df_cleaned, 'housing')\n",
    "impute_mode(df_cleaned, 'loan')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0KWGZjAFCwvW"
   },
   "source": [
    "# Preprocessing Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p-nlfCtJGbyt"
   },
   "outputs": [],
   "source": [
    "# Conver object columns to numerical for df\n",
    "# Function to determine if a column is numerical\n",
    "def is_numerical(column):\n",
    "    return pd.api.types.is_numeric_dtype(column)\n",
    "\n",
    "numerical_columns = [col for col in df.columns if is_numerical(df[col])]\n",
    "categorical_columns = [col for col in df.columns if not is_numerical(df[col])]\n",
    "\n",
    "# One-Hot Encoding for nominal categorical variables\n",
    "df = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Label Encoding for the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "df['y_yes'] = label_encoder.fit_transform(df['y_yes'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xi9t0MqzIkvL"
   },
   "outputs": [],
   "source": [
    "# Conver object columns to numerical for df_cleaned\n",
    "numerical_columns = [col for col in df_cleaned.columns if is_numerical(df_cleaned[col])]\n",
    "categorical_columns = [col for col in df_cleaned.columns if not is_numerical(df_cleaned[col])]\n",
    "\n",
    "# One-Hot Encoding for nominal categorical variables\n",
    "df_cleaned = pd.get_dummies(df_cleaned, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Label Encoding for the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "df_cleaned['y_yes'] = label_encoder.fit_transform(df_cleaned['y_yes'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OOhCKw6uJEFs"
   },
   "outputs": [],
   "source": [
    "# Handle outlier for df_clean data\n",
    "numeric_cols = df_cleaned.select_dtypes(include=[np.number]).columns\n",
    "# Handle outlier\n",
    "# Determine the lower and upper thresholds for clipping (1st and 99th percentiles)\n",
    "lower_bound = df_cleaned[numeric_cols].quantile(0.01)\n",
    "upper_bound = df_cleaned[numeric_cols].quantile(0.99)\n",
    "\n",
    "# Apply clipping\n",
    "df_cleaned = df_cleaned[numeric_cols].clip(lower=lower_bound, upper=upper_bound, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cakcXawfLRZp"
   },
   "outputs": [],
   "source": [
    "X = df.drop(columns=['y_yes'])\n",
    "# Keep feature names\n",
    "X_feature_names = X.columns\n",
    "y = df['y_yes']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q2TASX5uL7tS"
   },
   "outputs": [],
   "source": [
    "X_cleaned = df_cleaned.drop(columns=['y_yes'])\n",
    "# Keep feature names\n",
    "X_cleaned_feature_names = X_cleaned.columns\n",
    "y_cleaned = df_cleaned['y_yes']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ubOFvd0PxjQx"
   },
   "outputs": [],
   "source": [
    "#split for both data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n",
    "X_cleaned_train, X_cleaned_test, y_cleaned_train, y_cleaned_test = train_test_split(\n",
    "    X_cleaned, y_cleaned, test_size=0.2, random_state=42, stratify=y_cleaned\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_cleaned_train_scaled = scaler.fit_transform(X_cleaned_train)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_cleaned_test_scaled = scaler.fit_transform(X_cleaned_test)\n",
    "X_test_scaled = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1717381197919,
     "user": {
      "displayName": "Shirley liu",
      "userId": "04876526516659009918"
     },
     "user_tz": 420
    },
    "id": "7i79Fy14MPGg",
    "outputId": "f981b83e-e0ac-4c01-b027-e844ba0a5725"
   },
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X_train_scaled)\n",
    "\n",
    "# Calculate cumulative explained variance\n",
    "cumulative_explained_variance = pca.explained_variance_ratio_.cumsum()\n",
    "\n",
    "# Find the number of components for 98%, 95%, and 90% explained variance\n",
    "components_98 = next(i for i, cumulative_variance in enumerate(cumulative_explained_variance) if cumulative_variance >= 0.98) + 1\n",
    "components_95 = next(i for i, cumulative_variance in enumerate(cumulative_explained_variance) if cumulative_variance >= 0.95) + 1\n",
    "components_90 = next(i for i, cumulative_variance in enumerate(cumulative_explained_variance) if cumulative_variance >= 0.90) + 1\n",
    "\n",
    "# Calculate cumulative explained variance\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "# Plot the cumulative explained variance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(cumulative_explained_variance, marker='o')\n",
    "plt.axhline(y=0.95, color='r', linestyle='--')\n",
    "plt.axvline(x=components_95 - 1, color='g', linestyle='--')\n",
    "plt.title('Cumulative Explained Variance by Number of Principal Components for data not cleaned')\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print(f'Number of components for 98% explained variance for df : {components_98}')\n",
    "print(f'Number of components for 95% explained variance for df: {components_95}')\n",
    "print(f'Number of components for 90% explained variance for df: {components_90}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1717381210931,
     "user": {
      "displayName": "Shirley liu",
      "userId": "04876526516659009918"
     },
     "user_tz": 420
    },
    "id": "3-4k2tlKMaci",
    "outputId": "4680a56f-0bb9-4a3c-8be4-05458a129aa8"
   },
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X_cleaned_train_scaled)\n",
    "\n",
    "# Calculate cumulative explained variance\n",
    "cumulative_explained_variance = pca.explained_variance_ratio_.cumsum()\n",
    "\n",
    "# Find the number of components for 98%, 95%, and 90% explained variance\n",
    "components_98 = next(i for i, cumulative_variance in enumerate(cumulative_explained_variance) if cumulative_variance >= 0.98) + 1\n",
    "components_95 = next(i for i, cumulative_variance in enumerate(cumulative_explained_variance) if cumulative_variance >= 0.95) + 1\n",
    "components_90 = next(i for i, cumulative_variance in enumerate(cumulative_explained_variance) if cumulative_variance >= 0.90) + 1\n",
    "\n",
    "# Plot the cumulative explained variance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(cumulative_explained_variance, marker='o')\n",
    "plt.axhline(y=0.95, color='r', linestyle='--')\n",
    "plt.axvline(x=components_95 - 1, color='g', linestyle='--')\n",
    "plt.title('Cumulative Explained Variance by Number of Principal Components for data after cleaned')\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print(f'Number of components for 98% explained variance for df_cleaned after preprocessing: {components_98}')\n",
    "print(f'Number of components for 95% explained variance for df_cleaned after preprocessing: {components_95}')\n",
    "print(f'Number of components for 90% explained variance for df_cleaned after preprocessing: {components_90}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Xt1KLYSQdgk"
   },
   "source": [
    "# Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3393,
     "status": "ok",
     "timestamp": 1717381226534,
     "user": {
      "displayName": "Shirley liu",
      "userId": "04876526516659009918"
     },
     "user_tz": 420
    },
    "id": "lWyzWOPRbJSj",
    "outputId": "b3373769-ef96-4fa4-dab8-219072050424"
   },
   "outputs": [],
   "source": [
    "# Initialize LassoCV with cross-validation\n",
    "lasso_cv = LassoCV(alphas=None, cv=10, max_iter=10000)\n",
    "\n",
    "# Fit the model\n",
    "lasso_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best alpha\n",
    "best_alpha = lasso_cv.alpha_\n",
    "\n",
    "print(f\"Best alpha: {best_alpha}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2565,
     "status": "ok",
     "timestamp": 1717381272367,
     "user": {
      "displayName": "Shirley liu",
      "userId": "04876526516659009918"
     },
     "user_tz": 420
    },
    "id": "f6B3OGuYdKt8",
    "outputId": "cfc2ee55-bc16-4beb-89ec-c98bcdbeafd2"
   },
   "outputs": [],
   "source": [
    "# Initialize Lasso with the best alpha\n",
    "lasso = Lasso(alpha=best_alpha, max_iter=10000)\n",
    "\n",
    "# Fit the model\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the coefficients\n",
    "coefficients = lasso.coef_\n",
    "\n",
    "\n",
    "# Retrieve the coefficients\n",
    "coefficients = lasso.coef_\n",
    "\n",
    "# Plot the coefficients\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(coefficients)), coefficients, marker='o', linestyle='-', linewidth=2)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.title('Lasso Coefficients for data not cleaned')\n",
    "plt.xlabel('Feature Index')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Select non-zero coefficients\n",
    "selected_features_lasso = X_feature_names[coefficients != 0]\n",
    "\n",
    "print(\"Selected features by Lasso with best alpha:\")\n",
    "print(selected_features_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1478,
     "status": "ok",
     "timestamp": 1717381327947,
     "user": {
      "displayName": "Shirley liu",
      "userId": "04876526516659009918"
     },
     "user_tz": 420
    },
    "id": "WwloonRfeX8e",
    "outputId": "97ba1a0e-eac0-4ecf-f1a1-80de506be389"
   },
   "outputs": [],
   "source": [
    "# Initialize LassoCV with cross-validation\n",
    "lasso_cv = LassoCV(alphas=None, cv=10, max_iter=10000)\n",
    "\n",
    "# Fit the model\n",
    "lasso_cv.fit(X_cleaned_train_scaled, y_cleaned_train)\n",
    "\n",
    "# Get the best alpha\n",
    "best_alpha_cleaned = lasso_cv.alpha_\n",
    "\n",
    "print(f\"Best alpha for cleaned data: {best_alpha_cleaned}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 695,
     "status": "ok",
     "timestamp": 1717381344762,
     "user": {
      "displayName": "Shirley liu",
      "userId": "04876526516659009918"
     },
     "user_tz": 420
    },
    "id": "ZBE19WFpeiRM",
    "outputId": "64b84f5d-4bc2-4d4a-daed-a2e95662caa5"
   },
   "outputs": [],
   "source": [
    "# Initialize Lasso with the best alpha\n",
    "lasso = Lasso(alpha=best_alpha_cleaned, max_iter=10000)\n",
    "\n",
    "# Fit the model\n",
    "lasso.fit(X_cleaned_train_scaled, y_cleaned_train)\n",
    "\n",
    "# Get the coefficients\n",
    "coefficients = lasso.coef_\n",
    "\n",
    "# Plot the coefficients\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(coefficients)), coefficients, marker='o', linestyle='-', linewidth=2)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.title('Lasso Coefficients for data cleaned')\n",
    "plt.xlabel('Feature Index')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Select non-zero coefficients\n",
    "selected_features_lasso_cleaned = X_cleaned_feature_names[coefficients != 0]\n",
    "\n",
    "print(\"Selected features by Lasso with best alpha for cleaned data:\")\n",
    "print(selected_features_lasso_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j49fpyklltfY"
   },
   "source": [
    "# Create new data set with top features from Lasso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DJQrotJoqj45"
   },
   "outputs": [],
   "source": [
    "\n",
    "X_selected = X[selected_features_lasso]\n",
    "X_selected_cleaned = X_cleaned[selected_features_lasso_cleaned]\n",
    "\n",
    "#split for both data\n",
    "X_selected_train, X_selected_test, y_selected_train, y_selected_test = train_test_split(X_selected, y, test_size=0.2, random_state=42,stratify=y)\n",
    "X_selected_cleaned_train, X_selected_cleaned_test, y_selected_cleaned_train, y_selected_cleaned_test = train_test_split(\n",
    "    X_selected_cleaned, y_cleaned, test_size=0.2, random_state=42, stratify=y_cleaned\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_selected_cleaned_train_scaled = scaler.fit_transform(X_selected_cleaned_train)\n",
    "X_selected_train_scaled = scaler.fit_transform(X_selected_train)\n",
    "X_selected_cleaned_test_scaled = scaler.fit_transform(X_selected_cleaned_test)\n",
    "X_selected_test_scaled = scaler.fit_transform(X_selected_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cOeqYK2wLsq3"
   },
   "source": [
    "# Compute the base line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 610,
     "status": "ok",
     "timestamp": 1717386493530,
     "user": {
      "displayName": "Shirley liu",
      "userId": "04876526516659009918"
     },
     "user_tz": 420
    },
    "id": "cFVHQckzLyHU",
    "outputId": "43652c43-3a13-47f4-e783-552bf48f47f4"
   },
   "outputs": [],
   "source": [
    "# Establish the baseline performance\n",
    "majority_class = pd.Series(y_selected_train).mode()[0]\n",
    "baseline_accuracy = (y_selected_test == majority_class).mean()\n",
    "\n",
    "print(\"Majority class in the training set: \", majority_class)\n",
    "print(\"Baseline accuracy (majority class classifier): \", baseline_accuracy)\n",
    "\n",
    "# Establish the baseline performance\n",
    "majority_class = pd.Series(y_selected_cleaned_train).mode()[0]\n",
    "baseline_accuracy = (y_selected_cleaned_test == majority_class).mean()\n",
    "\n",
    "print(\"Majority class in the training set with selected fature after clean : \", majority_class)\n",
    "print(\"Baseline accuracy (majority class classifier) with selected fature after clean : \", baseline_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQRtwno9MlNh"
   },
   "source": [
    "# Use Logistic Regression to build a basic model on your data and score the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 855,
     "status": "ok",
     "timestamp": 1717386545026,
     "user": {
      "displayName": "Shirley liu",
      "userId": "04876526516659009918"
     },
     "user_tz": 420
    },
    "id": "PuPylFnLMkV-",
    "outputId": "2596111c-05a3-467e-af2d-a1f09d7aa5fc"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Training Logistic Regression model\n",
    "model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "model.fit(X_selected_train_scaled, y_selected_train)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred = model.predict(X_selected_test_scaled)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_selected_test, y_pred)\n",
    "class_report = classification_report(y_selected_test, y_pred)\n",
    "\n",
    "print(\"Logistic Regression Model Accuracy: \", accuracy)\n",
    "print(\"\\nClassification Report:\\n\", class_report)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_selected_test, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the coefficients\n",
    "coefficients = model.coef_[0]\n",
    "feature_names = [f'Feature {i}' for i in range(X_selected_train_scaled.shape[1])]\n",
    "\n",
    "# Plot the coefficients\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(feature_names, coefficients)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.title('Logistic Regression Coefficients')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = model.predict_proba(X_selected_train_scaled)[:, 1]\n",
    "# Compute ROC curve and AUC\n",
    "fpr, tpr, _ = roc_curve(y_selected_train, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 401,
     "status": "ok",
     "timestamp": 1717386684713,
     "user": {
      "displayName": "Shirley liu",
      "userId": "04876526516659009918"
     },
     "user_tz": 420
    },
    "id": "GvrrO2bjNz9o",
    "outputId": "a51a5f13-15b1-43f3-ef61-ac316c73b36e"
   },
   "outputs": [],
   "source": [
    "# Training Logistic Regression model\n",
    "model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "model.fit(X_selected_cleaned_train_scaled, y_selected_cleaned_train)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred = model.predict(X_selected_cleaned_test_scaled)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_selected_cleaned_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_selected_cleaned_test, y_pred)\n",
    "class_report = classification_report(y_selected_cleaned_test, y_pred)\n",
    "\n",
    "print(\"cleaned data - Logistic Regression Model Accuracy: \", accuracy)\n",
    "print(\"\\nCleaned data - Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nCleaned data -  Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRzryr0rOrG7"
   },
   "source": [
    "# Model Comparisons with default model \n",
    "\n",
    "Now, we aim to compare the performance of the Logistic Regression model to our KNN algorithm, Decision Tree, and SVM models. Using the default settings for each of the models, fit and score each. Also, be sure to compare the fit time of each of the models. Present your findings in a DataFrame similar to that below:\n",
    "Model\tTrain Time\tTrain Accuracy\tTest Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68643,
     "status": "ok",
     "timestamp": 1717387271513,
     "user": {
      "displayName": "Shirley liu",
      "userId": "04876526516659009918"
     },
     "user_tz": 420
    },
    "id": "tD6mxW6vOcU5",
    "outputId": "0a882975-2346-41c8-e535-21383f4944c8"
   },
   "outputs": [],
   "source": [
    "# List of models to evaluate\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Support Vector Machine': SVC()\n",
    "}\n",
    "\n",
    "# DataFrame to store the results\n",
    "results = pd.DataFrame(columns=['Model', 'Train Time', 'Train Accuracy', 'Test Accuracy'])\n",
    "\n",
    "# Train, evaluate, and record the results for each model\n",
    "for model_name, model in models.items():\n",
    "    start_time = time.time()\n",
    "    model.fit(X_selected_train_scaled, y_selected_train)\n",
    "    train_time = time.time() - start_time\n",
    "\n",
    "    train_accuracy = accuracy_score(y_selected_train, model.predict(X_selected_train_scaled))\n",
    "    test_accuracy = accuracy_score(y_selected_test, model.predict(X_selected_test_scaled))\n",
    "\n",
    "    result = pd.DataFrame([[model_name, train_time, train_accuracy, test_accuracy]],\n",
    "                          columns=['Model', 'Train Time', 'Train Accuracy', 'Test Accuracy'])\n",
    "\n",
    "    results = pd.concat([results, result], ignore_index=True)\n",
    "\n",
    "# Display the results\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39582,
     "status": "ok",
     "timestamp": 1717387570481,
     "user": {
      "displayName": "Shirley liu",
      "userId": "04876526516659009918"
     },
     "user_tz": 420
    },
    "id": "U9kV3-2CRES2",
    "outputId": "120a9e05-87b1-4db9-9a81-4dd88cc1ba06"
   },
   "outputs": [],
   "source": [
    "# List of models to evaluate\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Support Vector Machine': SVC()\n",
    "}\n",
    "\n",
    "# DataFrame to store the results\n",
    "results = pd.DataFrame(columns=['Model', 'Train Time', 'Train Accuracy', 'Test Accuracy'])\n",
    "\n",
    "# Train, evaluate, and record the results for each model\n",
    "for model_name, model in models.items():\n",
    "    start_time = time.time()\n",
    "    model.fit(X_selected_cleaned_train_scaled, y_selected_cleaned_train)\n",
    "    train_time = time.time() - start_time\n",
    "\n",
    "    train_accuracy = accuracy_score(y_selected_cleaned_train, model.predict(X_selected_cleaned_train_scaled))\n",
    "    test_accuracy = accuracy_score(y_selected_cleaned_test, model.predict(X_selected_cleaned_test_scaled))\n",
    "\n",
    "    result = pd.DataFrame([[model_name, train_time, train_accuracy, test_accuracy]],\n",
    "                          columns=['Model', 'Train Time', 'Train Accuracy', 'Test Accuracy'])\n",
    "\n",
    "    results = pd.concat([results, result], ignore_index=True)\n",
    "\n",
    "# Display the results\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 73588,
     "status": "ok",
     "timestamp": 1717387890176,
     "user": {
      "displayName": "Shirley liu",
      "userId": "04876526516659009918"
     },
     "user_tz": 420
    },
    "id": "Ob26RBBYSDj-",
    "outputId": "69c385fe-5309-491b-f184-129616eecace"
   },
   "outputs": [],
   "source": [
    "# List of models to evaluate\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Support Vector Machine': SVC()\n",
    "}\n",
    "\n",
    "# DataFrame to store the results\n",
    "results = pd.DataFrame(columns=['Model', 'Train Time', 'Train Accuracy', 'Test Accuracy'])\n",
    "\n",
    "# Train, evaluate, and record the results for each model\n",
    "for model_name, model in models.items():\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, model.predict(X_train_scaled))\n",
    "    test_accuracy = accuracy_score(y_test, model.predict(X_test_scaled))\n",
    "\n",
    "    result = pd.DataFrame([[model_name, train_time, train_accuracy, test_accuracy]],\n",
    "                          columns=['Model', 'Train Time', 'Train Accuracy', 'Test Accuracy'])\n",
    "\n",
    "    results = pd.concat([results, result], ignore_index=True)\n",
    "\n",
    "# Display the results\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXVLsZKDTdjN"
   },
   "source": [
    "# Using gridseachCV to find best hyperparameter and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "B7h8MKKwTaWQ",
    "outputId": "9b4c7d75-c1d3-436f-965b-053aabde3546"
   },
   "outputs": [],
   "source": [
    "\n",
    "# List of models to evaluate with parameter grids\n",
    "models = {\n",
    "    'Logistic Regression': (LogisticRegression(max_iter=1000), {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'solver': ['liblinear', 'saga'],\n",
    "        'max_iter': [5000]\n",
    "    }),\n",
    "    'K-Nearest Neighbors': (KNeighborsClassifier(), {\n",
    "        'n_neighbors': [3, 5, 7, 9],\n",
    "        'weights': ['uniform', 'distance']\n",
    "    }),\n",
    "    'Decision Tree': (DecisionTreeClassifier(), {\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    }),\n",
    "    'Support Vector Machine': (SVC(), {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'max_iter': [5000]\n",
    "    })\n",
    "}\n",
    "\n",
    "# DataFrame to store the results\n",
    "results = pd.DataFrame(columns=['Model', 'Train Time', 'Train Accuracy', 'Test Accuracy'])\n",
    "\n",
    "# Train, evaluate, and record the results for each model\n",
    "for model_name, (model, param_grid) in models.items():\n",
    "    start_time = time.time()\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "    grid_search.fit(X_selected_train_scaled, y_selected_train)\n",
    "    train_time = time.time() - start_time\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    train_accuracy = accuracy_score(y_selected_train, best_model.predict(X_selected_train_scaled))\n",
    "    test_accuracy = accuracy_score(y_selected_test, best_model.predict(X_selected_test_scaled))\n",
    "\n",
    "    result = pd.DataFrame([[model_name, train_time, train_accuracy, test_accuracy]],\n",
    "                          columns=['Model', 'Train Time', 'Train Accuracy', 'Test Accuracy'])\n",
    "\n",
    "    results = pd.concat([results, result], ignore_index=True)\n",
    "\n",
    "# Display the results\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "nTCuRhSMidyF"
   },
   "outputs": [],
   "source": [
    "# List of models to evaluate with parameter grids\n",
    "models = {\n",
    "    'Logistic Regression': (LogisticRegression(max_iter=1000), {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'solver': ['liblinear', 'saga'],\n",
    "        'max_iter': [5000]\n",
    "    }),\n",
    "    'K-Nearest Neighbors': (KNeighborsClassifier(), {\n",
    "        'n_neighbors': [3, 5, 7, 9],\n",
    "        'weights': ['uniform', 'distance']\n",
    "    }),\n",
    "    'Decision Tree': (DecisionTreeClassifier(), {\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    }),\n",
    "    'Support Vector Machine': (SVC(), {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'max_iter': [5000]\n",
    "    })\n",
    "}\n",
    "\n",
    "# DataFrame to store the results\n",
    "results = pd.DataFrame(columns=['Model', 'Train Time', 'Train Accuracy', 'Test Accuracy'])\n",
    "\n",
    "# Train, evaluate, and record the results for each model\n",
    "for model_name, (model, param_grid) in models.items():\n",
    "    start_time = time.time()\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    train_accuracy = accuracy_score(y_train, best_model.predict(X_train_scaled))\n",
    "    test_accuracy = accuracy_score(y_test, best_model.predict(X_test_scaled))\n",
    "\n",
    "    result = pd.DataFrame([[model_name, train_time, train_accuracy, test_accuracy]],\n",
    "                          columns=['Model', 'Train Time', 'Train Accuracy', 'Test Accuracy'])\n",
    "\n",
    "    results = pd.concat([results, result], ignore_index=True)\n",
    "\n",
    "# Display the results\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Wqb7xvoJixPX"
   },
   "outputs": [],
   "source": [
    "# List of models to evaluate with parameter grids\n",
    "models = {\n",
    "    'Logistic Regression': (LogisticRegression(max_iter=1000), {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'solver': ['liblinear', 'saga'],\n",
    "        'max_iter': [5000]\n",
    "    }),\n",
    "    'K-Nearest Neighbors': (KNeighborsClassifier(), {\n",
    "        'n_neighbors': [3, 5, 7, 9],\n",
    "        'weights': ['uniform', 'distance']\n",
    "    }),\n",
    "    'Decision Tree': (DecisionTreeClassifier(), {\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    }),\n",
    "    'Support Vector Machine': (SVC(), {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'max_iter': [5000]\n",
    "    })\n",
    "}\n",
    "\n",
    "# DataFrame to store the results\n",
    "results = pd.DataFrame(columns=['Model', 'Train Time', 'Train Accuracy', 'Test Accuracy'])\n",
    "\n",
    "# Train, evaluate, and record the results for each model\n",
    "for model_name, (model, param_grid) in models.items():\n",
    "    start_time = time.time()\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "    grid_search.fit(X_selected_cleaned_train_scaled, y_selected_cleaned_train)\n",
    "    train_time = time.time() - start_time\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    train_accuracy = accuracy_score(y_selected_cleaned_train, best_model.predict(X_selected_cleaned_train_scaled))\n",
    "    test_accuracy = accuracy_score(y_selected_cleaned_test, best_model.predict(X_selected_cleaned_test_scaled))\n",
    "\n",
    "    result = pd.DataFrame([[model_name, train_time, train_accuracy, test_accuracy]],\n",
    "                          columns=['Model', 'Train Time', 'Train Accuracy', 'Test Accuracy'])\n",
    "\n",
    "    results = pd.concat([results, result], ignore_index=True)\n",
    "\n",
    "# Display the results\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPhH103mp1WbGlcOU/ZbEuF",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
